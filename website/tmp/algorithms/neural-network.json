{
  "slug": "neural-network",
  "name": "Neural Network",
  "categories": ["machinelearning"],
  "body": {},
  "implementations": {
    "c-plus-plus": {
      "dir": "machine_learning/neural_network.cpp",
      "url": "https://github.com/TheAlgorithms/c-plus-plus/tree/master/machine_learning/neural_network.cpp",
      "code": "<span class=\"hljs-comment\">/**\n * @file\n * @author [Deep Raval](https://github.com/imdeep2905)\n *\n * @brief Implementation of [Multilayer Perceptron]\n * (https://en.wikipedia.org/wiki/Multilayer_perceptron).\n *\n * @details\n * A multilayer perceptron (MLP) is a class of feedforward artificial neural\n * network (ANN). The term MLP is used ambiguously, sometimes loosely to any\n * feedforward ANN, sometimes strictly to refer to networks composed of multiple\n * layers of perceptrons (with threshold activation). Multilayer perceptrons are\n * sometimes colloquially referred to as &quot;vanilla&quot; neural networks, especially\n * when they have a single hidden layer.\n *\n * An MLP consists of at least three layers of nodes: an input layer, a hidden\n * layer and an output layer. Except for the input nodes, each node is a neuron\n * that uses a nonlinear activation function. MLP utilizes a supervised learning\n * technique called backpropagation for training. Its multiple layers and\n * non-linear activation distinguish MLP from a linear perceptron. It can\n * distinguish data that is not linearly separable.\n *\n * See [Backpropagation](https://en.wikipedia.org/wiki/Backpropagation) for\n * training algorithm.\n *\n * \\note This implementation uses mini-batch gradient descent as optimizer and\n * MSE as loss function. Bias is also not included.\n */</span>\n\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;algorithm&gt;</span></span>\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;cassert&gt;</span></span>\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;chrono&gt;</span></span>\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;cmath&gt;</span></span>\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;fstream&gt;</span></span>\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span>\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;sstream&gt;</span></span>\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;string&gt;</span></span>\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;valarray&gt;</span></span>\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span>\n\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&quot;vector_ops.hpp&quot;</span>  <span class=\"hljs-comment\">// Custom header file for vector operations</span></span>\n\n<span class=\"hljs-comment\">/** \\namespace machine_learning\n * \\brief Machine learning algorithms\n */</span>\n<span class=\"hljs-keyword\">namespace</span> machine_learning {\n<span class=\"hljs-comment\">/** \\namespace neural_network\n * \\brief Neural Network or Multilayer Perceptron\n */</span>\n<span class=\"hljs-keyword\">namespace</span> neural_network {\n<span class=\"hljs-comment\">/** \\namespace activations\n * \\brief Various activation functions used in Neural network\n */</span>\n<span class=\"hljs-keyword\">namespace</span> activations {\n<span class=\"hljs-comment\">/**\n * Sigmoid function\n * @param X Value\n * @return Returns sigmoid(x)\n */</span>\n<span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">sigmoid</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">double</span> &amp;x)</span> </span>{ <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">1.0</span> / (<span class=\"hljs-number\">1.0</span> + std::<span class=\"hljs-built_in\">exp</span>(-x)); }\n\n<span class=\"hljs-comment\">/**\n * Derivative of sigmoid function\n * @param X Value\n * @return Returns derivative of sigmoid(x)\n */</span>\n<span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">dsigmoid</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">double</span> &amp;x)</span> </span>{ <span class=\"hljs-keyword\">return</span> x * (<span class=\"hljs-number\">1</span> - x); }\n\n<span class=\"hljs-comment\">/**\n * Relu function\n * @param X Value\n * @returns relu(x)\n */</span>\n<span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">relu</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">double</span> &amp;x)</span> </span>{ <span class=\"hljs-keyword\">return</span> std::<span class=\"hljs-built_in\">max</span>(<span class=\"hljs-number\">0.0</span>, x); }\n\n<span class=\"hljs-comment\">/**\n * Derivative of relu function\n * @param X Value\n * @returns derivative of relu(x)\n */</span>\n<span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">drelu</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">double</span> &amp;x)</span> </span>{ <span class=\"hljs-keyword\">return</span> x &gt;= <span class=\"hljs-number\">0.0</span> ? <span class=\"hljs-number\">1.0</span> : <span class=\"hljs-number\">0.0</span>; }\n\n<span class=\"hljs-comment\">/**\n * Tanh function\n * @param X Value\n * @return Returns tanh(x)\n */</span>\n<span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">tanh</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">double</span> &amp;x)</span> </span>{ <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">2</span> / (<span class=\"hljs-number\">1</span> + std::<span class=\"hljs-built_in\">exp</span>(<span class=\"hljs-number\">-2</span> * x)) - <span class=\"hljs-number\">1</span>; }\n\n<span class=\"hljs-comment\">/**\n * Derivative of Sigmoid function\n * @param X Value\n * @return Returns derivative of tanh(x)\n */</span>\n<span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">dtanh</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">double</span> &amp;x)</span> </span>{ <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">1</span> - x * x; }\n}  <span class=\"hljs-comment\">// namespace activations</span>\n<span class=\"hljs-comment\">/** \\namespace util_functions\n * \\brief Various utility functions used in Neural network\n */</span>\n<span class=\"hljs-keyword\">namespace</span> util_functions {\n<span class=\"hljs-comment\">/**\n * Square function\n * @param X Value\n * @return Returns x * x\n */</span>\n<span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">square</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">double</span> &amp;x)</span> </span>{ <span class=\"hljs-keyword\">return</span> x * x; }\n<span class=\"hljs-comment\">/**\n * Identity function\n * @param X Value\n * @return Returns x\n */</span>\n<span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">identity_function</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">double</span> &amp;x)</span> </span>{ <span class=\"hljs-keyword\">return</span> x; }\n}  <span class=\"hljs-comment\">// namespace util_functions</span>\n<span class=\"hljs-comment\">/** \\namespace layers\n * \\brief This namespace contains layers used\n * in MLP.\n */</span>\n<span class=\"hljs-keyword\">namespace</span> layers {\n<span class=\"hljs-comment\">/**\n * neural_network::layers::DenseLayer class is used to store all necessary\n * information about the layers (i.e. neurons, activation and kernel). This\n * class is used by NeuralNetwork class to store layers.\n *\n */</span>\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">DenseLayer</span> {\n <span class=\"hljs-keyword\">public</span>:\n    <span class=\"hljs-comment\">// To store activation function and it&#x27;s derivative</span>\n    <span class=\"hljs-built_in\">double</span> (*activation_function)(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">double</span> &amp;);\n    <span class=\"hljs-built_in\">double</span> (*dactivation_function)(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">double</span> &amp;);\n    <span class=\"hljs-type\">int</span> neurons;             <span class=\"hljs-comment\">// To store number of neurons (used in summary)</span>\n    std::string activation;  <span class=\"hljs-comment\">// To store activation name (used in summary)</span>\n    std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt; kernel;  <span class=\"hljs-comment\">// To store kernel (aka weights)</span>\n\n    <span class=\"hljs-comment\">/**\n     * Constructor for neural_network::layers::DenseLayer class\n     * @param neurons number of neurons\n     * @param activation activation function for layer\n     * @param kernel_shape shape of kernel\n     * @param random_kernel flag for whether to intialize kernel randomly\n     */</span>\n    <span class=\"hljs-built_in\">DenseLayer</span>(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">int</span> &amp;neurons, <span class=\"hljs-keyword\">const</span> std::string &amp;activation,\n               <span class=\"hljs-keyword\">const</span> std::pair&lt;<span class=\"hljs-type\">size_t</span>, <span class=\"hljs-type\">size_t</span>&gt; &amp;kernel_shape,\n               <span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">bool</span> &amp;random_kernel) {\n        <span class=\"hljs-comment\">// Choosing activation (and it&#x27;s derivative)</span>\n        <span class=\"hljs-keyword\">if</span> (activation == <span class=\"hljs-string\">&quot;sigmoid&quot;</span>) {\n            activation_function = neural_network::activations::sigmoid;\n            dactivation_function = neural_network::activations::sigmoid;\n        } <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> (activation == <span class=\"hljs-string\">&quot;relu&quot;</span>) {\n            activation_function = neural_network::activations::relu;\n            dactivation_function = neural_network::activations::drelu;\n        } <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> (activation == <span class=\"hljs-string\">&quot;tanh&quot;</span>) {\n            activation_function = neural_network::activations::tanh;\n            dactivation_function = neural_network::activations::dtanh;\n        } <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> (activation == <span class=\"hljs-string\">&quot;none&quot;</span>) {\n            <span class=\"hljs-comment\">// Set identity function in casse of none is supplied</span>\n            activation_function =\n                neural_network::util_functions::identity_function;\n            dactivation_function =\n                neural_network::util_functions::identity_function;\n        } <span class=\"hljs-keyword\">else</span> {\n            <span class=\"hljs-comment\">// If supplied activation is invalid</span>\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;Invalid argument. Expected {none, sigmoid, relu, &quot;</span>\n                         <span class=\"hljs-string\">&quot;tanh} got &quot;</span>;\n            std::cerr &lt;&lt; activation &lt;&lt; std::endl;\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\n        }\n        <span class=\"hljs-keyword\">this</span>-&gt;activation = activation;  <span class=\"hljs-comment\">// Setting activation name</span>\n        <span class=\"hljs-keyword\">this</span>-&gt;neurons = neurons;        <span class=\"hljs-comment\">// Setting number of neurons</span>\n        <span class=\"hljs-comment\">// Initialize kernel according to flag</span>\n        <span class=\"hljs-keyword\">if</span> (random_kernel) {\n            <span class=\"hljs-built_in\">uniform_random_initialization</span>(kernel, kernel_shape, <span class=\"hljs-number\">-1.0</span>, <span class=\"hljs-number\">1.0</span>);\n        } <span class=\"hljs-keyword\">else</span> {\n            <span class=\"hljs-built_in\">unit_matrix_initialization</span>(kernel, kernel_shape);\n        }\n    }\n    <span class=\"hljs-comment\">/**\n     * Constructor for neural_network::layers::DenseLayer class\n     * @param neurons number of neurons\n     * @param activation activation function for layer\n     * @param kernel values of kernel (useful in loading model)\n     */</span>\n    <span class=\"hljs-built_in\">DenseLayer</span>(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">int</span> &amp;neurons, <span class=\"hljs-keyword\">const</span> std::string &amp;activation,\n               <span class=\"hljs-keyword\">const</span> std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt; &amp;kernel) {\n        <span class=\"hljs-comment\">// Choosing activation (and it&#x27;s derivative)</span>\n        <span class=\"hljs-keyword\">if</span> (activation == <span class=\"hljs-string\">&quot;sigmoid&quot;</span>) {\n            activation_function = neural_network::activations::sigmoid;\n            dactivation_function = neural_network::activations::sigmoid;\n        } <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> (activation == <span class=\"hljs-string\">&quot;relu&quot;</span>) {\n            activation_function = neural_network::activations::relu;\n            dactivation_function = neural_network::activations::drelu;\n        } <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> (activation == <span class=\"hljs-string\">&quot;tanh&quot;</span>) {\n            activation_function = neural_network::activations::tanh;\n            dactivation_function = neural_network::activations::dtanh;\n        } <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> (activation == <span class=\"hljs-string\">&quot;none&quot;</span>) {\n            <span class=\"hljs-comment\">// Set identity function in casse of none is supplied</span>\n            activation_function =\n                neural_network::util_functions::identity_function;\n            dactivation_function =\n                neural_network::util_functions::identity_function;\n        } <span class=\"hljs-keyword\">else</span> {\n            <span class=\"hljs-comment\">// If supplied activation is invalid</span>\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;Invalid argument. Expected {none, sigmoid, relu, &quot;</span>\n                         <span class=\"hljs-string\">&quot;tanh} got &quot;</span>;\n            std::cerr &lt;&lt; activation &lt;&lt; std::endl;\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\n        }\n        <span class=\"hljs-keyword\">this</span>-&gt;activation = activation;  <span class=\"hljs-comment\">// Setting activation name</span>\n        <span class=\"hljs-keyword\">this</span>-&gt;neurons = neurons;        <span class=\"hljs-comment\">// Setting number of neurons</span>\n        <span class=\"hljs-keyword\">this</span>-&gt;kernel = kernel;          <span class=\"hljs-comment\">// Setting supplied kernel values</span>\n    }\n\n    <span class=\"hljs-comment\">/**\n     * Copy Constructor for class DenseLayer.\n     *\n     * @param model instance of class to be copied.\n     */</span>\n    <span class=\"hljs-built_in\">DenseLayer</span>(<span class=\"hljs-keyword\">const</span> DenseLayer &amp;layer) = <span class=\"hljs-keyword\">default</span>;\n\n    <span class=\"hljs-comment\">/**\n     * Destructor for class DenseLayer.\n     */</span>\n    ~<span class=\"hljs-built_in\">DenseLayer</span>() = <span class=\"hljs-keyword\">default</span>;\n\n    <span class=\"hljs-comment\">/**\n     * Copy assignment operator for class DenseLayer\n     */</span>\n    DenseLayer &amp;<span class=\"hljs-keyword\">operator</span>=(<span class=\"hljs-keyword\">const</span> DenseLayer &amp;layer) = <span class=\"hljs-keyword\">default</span>;\n\n    <span class=\"hljs-comment\">/**\n     * Move constructor for class DenseLayer\n     */</span>\n    <span class=\"hljs-built_in\">DenseLayer</span>(DenseLayer &amp;&amp;) = <span class=\"hljs-keyword\">default</span>;\n\n    <span class=\"hljs-comment\">/**\n     * Move assignment operator for class DenseLayer\n     */</span>\n    DenseLayer &amp;<span class=\"hljs-keyword\">operator</span>=(DenseLayer &amp;&amp;) = <span class=\"hljs-keyword\">default</span>;\n};\n}  <span class=\"hljs-comment\">// namespace layers</span>\n<span class=\"hljs-comment\">/**\n * NeuralNetwork class is implements MLP. This class is\n * used by actual user to create and train networks.\n *\n */</span>\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">NeuralNetwork</span> {\n <span class=\"hljs-keyword\">private</span>:\n    std::vector&lt;neural_network::layers::DenseLayer&gt; layers;  <span class=\"hljs-comment\">// To store layers</span>\n    <span class=\"hljs-comment\">/**\n     * Private Constructor for class NeuralNetwork. This constructor\n     * is used internally to load model.\n     * @param config vector containing pair (neurons, activation)\n     * @param kernels vector containing all pretrained kernels\n     */</span>\n    <span class=\"hljs-built_in\">NeuralNetwork</span>(\n        <span class=\"hljs-keyword\">const</span> std::vector&lt;std::pair&lt;<span class=\"hljs-type\">int</span>, std::string&gt;&gt; &amp;config,\n        <span class=\"hljs-keyword\">const</span> std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; &amp;kernels) {\n        <span class=\"hljs-comment\">// First layer should not have activation</span>\n        <span class=\"hljs-keyword\">if</span> (config.<span class=\"hljs-built_in\">begin</span>()-&gt;second != <span class=\"hljs-string\">&quot;none&quot;</span>) {\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\n            std::cerr\n                &lt;&lt; <span class=\"hljs-string\">&quot;First layer can&#x27;t have activation other than none got &quot;</span>\n                &lt;&lt; config.<span class=\"hljs-built_in\">begin</span>()-&gt;second;\n            std::cerr &lt;&lt; std::endl;\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\n        }\n        <span class=\"hljs-comment\">// Network should have atleast two layers</span>\n        <span class=\"hljs-keyword\">if</span> (config.<span class=\"hljs-built_in\">size</span>() &lt;= <span class=\"hljs-number\">1</span>) {\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;Invalid size of network, &quot;</span>;\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;Atleast two layers are required&quot;</span>;\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\n        }\n        <span class=\"hljs-comment\">// Reconstructing all pretrained layers</span>\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &lt; config.<span class=\"hljs-built_in\">size</span>(); i++) {\n            layers.<span class=\"hljs-built_in\">emplace_back</span>(neural_network::layers::<span class=\"hljs-built_in\">DenseLayer</span>(\n                config[i].first, config[i].second, kernels[i]));\n        }\n        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;INFO: Network constructed successfully&quot;</span> &lt;&lt; std::endl;\n    }\n    <span class=\"hljs-comment\">/**\n     * Private function to get detailed predictions (i.e.\n     * activated neuron values). This function is used in\n     * backpropagation, single predict and batch predict.\n     * @param X input vector\n     */</span>\n    std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt;\n    __detailed_single_prediction(<span class=\"hljs-keyword\">const</span> std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt; &amp;X) {\n        std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; details;\n        std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt; current_pass = X;\n        details.<span class=\"hljs-built_in\">emplace_back</span>(X);\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">auto</span> &amp;l : layers) {\n            current_pass = <span class=\"hljs-built_in\">multiply</span>(current_pass, l.kernel);\n            current_pass = <span class=\"hljs-built_in\">apply_function</span>(current_pass, l.activation_function);\n            details.<span class=\"hljs-built_in\">emplace_back</span>(current_pass);\n        }\n        <span class=\"hljs-keyword\">return</span> details;\n    }\n\n <span class=\"hljs-keyword\">public</span>:\n    <span class=\"hljs-comment\">/**\n     * Default Constructor for class NeuralNetwork. This constructor\n     * is used to create empty variable of type NeuralNetwork class.\n     */</span>\n    <span class=\"hljs-built_in\">NeuralNetwork</span>() = <span class=\"hljs-keyword\">default</span>;\n\n    <span class=\"hljs-comment\">/**\n     * Constructor for class NeuralNetwork. This constructor\n     * is used by user.\n     * @param config vector containing pair (neurons, activation)\n     */</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">explicit</span> <span class=\"hljs-title\">NeuralNetwork</span><span class=\"hljs-params\">(\n        <span class=\"hljs-keyword\">const</span> std::vector&lt;std::pair&lt;<span class=\"hljs-type\">int</span>, std::string&gt;&gt; &amp;config)</span> </span>{\n        <span class=\"hljs-comment\">// First layer should not have activation</span>\n        <span class=\"hljs-keyword\">if</span> (config.<span class=\"hljs-built_in\">begin</span>()-&gt;second != <span class=\"hljs-string\">&quot;none&quot;</span>) {\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\n            std::cerr\n                &lt;&lt; <span class=\"hljs-string\">&quot;First layer can&#x27;t have activation other than none got &quot;</span>\n                &lt;&lt; config.<span class=\"hljs-built_in\">begin</span>()-&gt;second;\n            std::cerr &lt;&lt; std::endl;\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\n        }\n        <span class=\"hljs-comment\">// Network should have atleast two layers</span>\n        <span class=\"hljs-keyword\">if</span> (config.<span class=\"hljs-built_in\">size</span>() &lt;= <span class=\"hljs-number\">1</span>) {\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;Invalid size of network, &quot;</span>;\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;Atleast two layers are required&quot;</span>;\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\n        }\n        <span class=\"hljs-comment\">// Separately creating first layer so it can have unit matrix</span>\n        <span class=\"hljs-comment\">// as kernel.</span>\n        layers.<span class=\"hljs-built_in\">push_back</span>(neural_network::layers::<span class=\"hljs-built_in\">DenseLayer</span>(\n            config[<span class=\"hljs-number\">0</span>].first, config[<span class=\"hljs-number\">0</span>].second,\n            {config[<span class=\"hljs-number\">0</span>].first, config[<span class=\"hljs-number\">0</span>].first}, <span class=\"hljs-literal\">false</span>));\n        <span class=\"hljs-comment\">// Creating remaining layers</span>\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">1</span>; i &lt; config.<span class=\"hljs-built_in\">size</span>(); i++) {\n            layers.<span class=\"hljs-built_in\">push_back</span>(neural_network::layers::<span class=\"hljs-built_in\">DenseLayer</span>(\n                config[i].first, config[i].second,\n                {config[i - <span class=\"hljs-number\">1</span>].first, config[i].first}, <span class=\"hljs-literal\">true</span>));\n        }\n        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;INFO: Network constructed successfully&quot;</span> &lt;&lt; std::endl;\n    }\n\n    <span class=\"hljs-comment\">/**\n     * Copy Constructor for class NeuralNetwork.\n     *\n     * @param model instance of class to be copied.\n     */</span>\n    <span class=\"hljs-built_in\">NeuralNetwork</span>(<span class=\"hljs-keyword\">const</span> NeuralNetwork &amp;model) = <span class=\"hljs-keyword\">default</span>;\n\n    <span class=\"hljs-comment\">/**\n     * Destructor for class NeuralNetwork.\n     */</span>\n    ~<span class=\"hljs-built_in\">NeuralNetwork</span>() = <span class=\"hljs-keyword\">default</span>;\n\n    <span class=\"hljs-comment\">/**\n     * Copy assignment operator for class NeuralNetwork\n     */</span>\n    NeuralNetwork &amp;<span class=\"hljs-keyword\">operator</span>=(<span class=\"hljs-keyword\">const</span> NeuralNetwork &amp;model) = <span class=\"hljs-keyword\">default</span>;\n\n    <span class=\"hljs-comment\">/**\n     * Move constructor for class NeuralNetwork\n     */</span>\n    <span class=\"hljs-built_in\">NeuralNetwork</span>(NeuralNetwork &amp;&amp;) = <span class=\"hljs-keyword\">default</span>;\n\n    <span class=\"hljs-comment\">/**\n     * Move assignment operator for class NeuralNetwork\n     */</span>\n    NeuralNetwork &amp;<span class=\"hljs-keyword\">operator</span>=(NeuralNetwork &amp;&amp;) = <span class=\"hljs-keyword\">default</span>;\n\n    <span class=\"hljs-comment\">/**\n     * Function to get X and Y from csv file (where X = data, Y = label)\n     * @param file_name csv file name\n     * @param last_label flag for whether label is in first or last column\n     * @param normalize flag for whether to normalize data\n     * @param slip_lines number of lines to skip\n     * @return returns pair of X and Y\n     */</span>\n    std::pair&lt;std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt;,\n              std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt;&gt;\n    <span class=\"hljs-built_in\">get_XY_from_csv</span>(<span class=\"hljs-keyword\">const</span> std::string &amp;file_name, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">bool</span> &amp;last_label,\n                    <span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">bool</span> &amp;normalize, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">int</span> &amp;slip_lines = <span class=\"hljs-number\">1</span>) {\n        std::ifstream in_file;                          <span class=\"hljs-comment\">// Ifstream to read file</span>\n        in_file.<span class=\"hljs-built_in\">open</span>(file_name.<span class=\"hljs-built_in\">c_str</span>(), std::ios::in);  <span class=\"hljs-comment\">// Open file</span>\n        <span class=\"hljs-comment\">// If there is any problem in opening file</span>\n        <span class=\"hljs-keyword\">if</span> (!in_file.<span class=\"hljs-built_in\">is_open</span>()) {\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;Unable to open file: &quot;</span> &lt;&lt; file_name &lt;&lt; std::endl;\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\n        }\n        std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; X,\n            Y;             <span class=\"hljs-comment\">// To store X and Y</span>\n        std::string line;  <span class=\"hljs-comment\">// To store each line</span>\n        <span class=\"hljs-comment\">// Skip lines</span>\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; slip_lines; i++) {\n            std::<span class=\"hljs-built_in\">getline</span>(in_file, line, <span class=\"hljs-string\">&#x27;\\n&#x27;</span>);  <span class=\"hljs-comment\">// Ignore line</span>\n        }\n        <span class=\"hljs-comment\">// While file has information</span>\n        <span class=\"hljs-keyword\">while</span> (!in_file.<span class=\"hljs-built_in\">eof</span>() &amp;&amp; std::<span class=\"hljs-built_in\">getline</span>(in_file, line, <span class=\"hljs-string\">&#x27;\\n&#x27;</span>)) {\n            std::valarray&lt;<span class=\"hljs-type\">double</span>&gt; x_data,\n                y_data;                  <span class=\"hljs-comment\">// To store single sample and label</span>\n            <span class=\"hljs-function\">std::stringstream <span class=\"hljs-title\">ss</span><span class=\"hljs-params\">(line)</span></span>;  <span class=\"hljs-comment\">// Constructing stringstream from line</span>\n            std::string token;  <span class=\"hljs-comment\">// To store each token in line (seprated by &#x27;,&#x27;)</span>\n            <span class=\"hljs-keyword\">while</span> (std::<span class=\"hljs-built_in\">getline</span>(ss, token, <span class=\"hljs-string\">&#x27;,&#x27;</span>)) {  <span class=\"hljs-comment\">// For each token</span>\n                <span class=\"hljs-comment\">// Insert numerical value of token in x_data</span>\n                x_data = <span class=\"hljs-built_in\">insert_element</span>(x_data, std::<span class=\"hljs-built_in\">stod</span>(token));\n            }\n            <span class=\"hljs-comment\">// If label is in last column</span>\n            <span class=\"hljs-keyword\">if</span> (last_label) {\n                y_data.<span class=\"hljs-built_in\">resize</span>(<span class=\"hljs-keyword\">this</span>-&gt;layers.<span class=\"hljs-built_in\">back</span>().neurons);\n                <span class=\"hljs-comment\">// If task is classification</span>\n                <span class=\"hljs-keyword\">if</span> (y_data.<span class=\"hljs-built_in\">size</span>() &gt; <span class=\"hljs-number\">1</span>) {\n                    y_data[x_data[x_data.<span class=\"hljs-built_in\">size</span>() - <span class=\"hljs-number\">1</span>]] = <span class=\"hljs-number\">1</span>;\n                }\n                <span class=\"hljs-comment\">// If task is regrssion (of single value)</span>\n                <span class=\"hljs-keyword\">else</span> {\n                    y_data[<span class=\"hljs-number\">0</span>] = x_data[x_data.<span class=\"hljs-built_in\">size</span>() - <span class=\"hljs-number\">1</span>];\n                }\n                x_data = <span class=\"hljs-built_in\">pop_back</span>(x_data);  <span class=\"hljs-comment\">// Remove label from x_data</span>\n            } <span class=\"hljs-keyword\">else</span> {\n                y_data.<span class=\"hljs-built_in\">resize</span>(<span class=\"hljs-keyword\">this</span>-&gt;layers.<span class=\"hljs-built_in\">back</span>().neurons);\n                <span class=\"hljs-comment\">// If task is classification</span>\n                <span class=\"hljs-keyword\">if</span> (y_data.<span class=\"hljs-built_in\">size</span>() &gt; <span class=\"hljs-number\">1</span>) {\n                    y_data[x_data[x_data.<span class=\"hljs-built_in\">size</span>() - <span class=\"hljs-number\">1</span>]] = <span class=\"hljs-number\">1</span>;\n                }\n                <span class=\"hljs-comment\">// If task is regrssion (of single value)</span>\n                <span class=\"hljs-keyword\">else</span> {\n                    y_data[<span class=\"hljs-number\">0</span>] = x_data[x_data.<span class=\"hljs-built_in\">size</span>() - <span class=\"hljs-number\">1</span>];\n                }\n                x_data = <span class=\"hljs-built_in\">pop_front</span>(x_data);  <span class=\"hljs-comment\">// Remove label from x_data</span>\n            }\n            <span class=\"hljs-comment\">// Push collected X_data and y_data in X and Y</span>\n            X.<span class=\"hljs-built_in\">push_back</span>({x_data});\n            Y.<span class=\"hljs-built_in\">push_back</span>({y_data});\n        }\n        <span class=\"hljs-comment\">// Normalize training data if flag is set</span>\n        <span class=\"hljs-keyword\">if</span> (normalize) {\n            <span class=\"hljs-comment\">// Scale data between 0 and 1 using min-max scaler</span>\n            X = <span class=\"hljs-built_in\">minmax_scaler</span>(X, <span class=\"hljs-number\">0.01</span>, <span class=\"hljs-number\">1.0</span>);\n        }\n        in_file.<span class=\"hljs-built_in\">close</span>();         <span class=\"hljs-comment\">// Closing file</span>\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">make_pair</span>(X, Y);  <span class=\"hljs-comment\">// Return pair of X and Y</span>\n    }\n\n    <span class=\"hljs-comment\">/**\n     * Function to get prediction of model on single sample.\n     * @param X array of feature vectors\n     * @return returns predictions as vector\n     */</span>\n    std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt; <span class=\"hljs-built_in\">single_predict</span>(\n        <span class=\"hljs-keyword\">const</span> std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt; &amp;X) {\n        <span class=\"hljs-comment\">// Get activations of all layers</span>\n        <span class=\"hljs-keyword\">auto</span> activations = <span class=\"hljs-keyword\">this</span>-&gt;__detailed_single_prediction(X);\n        <span class=\"hljs-comment\">// Return activations of last layer (actual predicted values)</span>\n        <span class=\"hljs-keyword\">return</span> activations.<span class=\"hljs-built_in\">back</span>();\n    }\n\n    <span class=\"hljs-comment\">/**\n     * Function to get prediction of model on batch\n     * @param X array of feature vectors\n     * @return returns predicted values as vector\n     */</span>\n    std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; <span class=\"hljs-built_in\">batch_predict</span>(\n        <span class=\"hljs-keyword\">const</span> std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; &amp;X) {\n        <span class=\"hljs-comment\">// Store predicted values</span>\n        std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; <span class=\"hljs-built_in\">predicted_batch</span>(\n            X.<span class=\"hljs-built_in\">size</span>());\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &lt; X.<span class=\"hljs-built_in\">size</span>(); i++) {  <span class=\"hljs-comment\">// For every sample</span>\n            <span class=\"hljs-comment\">// Push predicted values</span>\n            predicted_batch[i] = <span class=\"hljs-keyword\">this</span>-&gt;<span class=\"hljs-built_in\">single_predict</span>(X[i]);\n        }\n        <span class=\"hljs-keyword\">return</span> predicted_batch;  <span class=\"hljs-comment\">// Return predicted values</span>\n    }\n\n    <span class=\"hljs-comment\">/**\n     * Function to fit model on supplied data\n     * @param X array of feature vectors\n     * @param Y array of target values\n     * @param epochs number of epochs (default = 100)\n     * @param learning_rate learning rate (default = 0.01)\n     * @param batch_size batch size for gradient descent (default = 32)\n     * @param shuffle flag for whether to shuffle data (default = true)\n     */</span>\n    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">fit</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; &amp;X_,\n             <span class=\"hljs-keyword\">const</span> std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; &amp;Y_,\n             <span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">int</span> &amp;epochs = <span class=\"hljs-number\">100</span>, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">double</span> &amp;learning_rate = <span class=\"hljs-number\">0.01</span>,\n             <span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">size_t</span> &amp;batch_size = <span class=\"hljs-number\">32</span>, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">bool</span> &amp;shuffle = <span class=\"hljs-literal\">true</span>)</span> </span>{\n        std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; X = X_, Y = Y_;\n        <span class=\"hljs-comment\">// Both label and input data should have same size</span>\n        <span class=\"hljs-keyword\">if</span> (X.<span class=\"hljs-built_in\">size</span>() != Y.<span class=\"hljs-built_in\">size</span>()) {\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;X and Y in fit have different sizes&quot;</span> &lt;&lt; std::endl;\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\n        }\n        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;INFO: Training Started&quot;</span> &lt;&lt; std::endl;\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> epoch = <span class=\"hljs-number\">1</span>; epoch &lt;= epochs; epoch++) {  <span class=\"hljs-comment\">// For every epoch</span>\n            <span class=\"hljs-comment\">// Shuffle X and Y if flag is set</span>\n            <span class=\"hljs-keyword\">if</span> (shuffle) {\n                <span class=\"hljs-built_in\">equal_shuffle</span>(X, Y);\n            }\n            <span class=\"hljs-keyword\">auto</span> start =\n                std::chrono::high_resolution_clock::<span class=\"hljs-built_in\">now</span>();  <span class=\"hljs-comment\">// Start clock</span>\n            <span class=\"hljs-type\">double</span> loss = <span class=\"hljs-number\">0</span>,\n                   acc = <span class=\"hljs-number\">0</span>;  <span class=\"hljs-comment\">// Intialize performance metrics with zero</span>\n            <span class=\"hljs-comment\">// For each starting index of batch</span>\n            <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> batch_start = <span class=\"hljs-number\">0</span>; batch_start &lt; X.<span class=\"hljs-built_in\">size</span>();\n                 batch_start += batch_size) {\n                <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = batch_start;\n                     i &lt; std::<span class=\"hljs-built_in\">min</span>(X.<span class=\"hljs-built_in\">size</span>(), batch_start + batch_size); i++) {\n                    std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt; grad, cur_error,\n                        predicted;\n                    <span class=\"hljs-keyword\">auto</span> activations = <span class=\"hljs-keyword\">this</span>-&gt;__detailed_single_prediction(X[i]);\n                    <span class=\"hljs-comment\">// Gradients vector to store gradients for all layers</span>\n                    <span class=\"hljs-comment\">// They will be averaged and applied to kernel</span>\n                    std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; gradients;\n                    gradients.<span class=\"hljs-built_in\">resize</span>(<span class=\"hljs-keyword\">this</span>-&gt;layers.<span class=\"hljs-built_in\">size</span>());\n                    <span class=\"hljs-comment\">// First intialize gradients to zero</span>\n                    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &lt; gradients.<span class=\"hljs-built_in\">size</span>(); i++) {\n                        <span class=\"hljs-built_in\">zeroes_initialization</span>(\n                            gradients[i], <span class=\"hljs-built_in\">get_shape</span>(<span class=\"hljs-keyword\">this</span>-&gt;layers[i].kernel));\n                    }\n                    predicted = activations.<span class=\"hljs-built_in\">back</span>();  <span class=\"hljs-comment\">// Predicted vector</span>\n                    cur_error = predicted - Y[i];    <span class=\"hljs-comment\">// Absoulute error</span>\n                    <span class=\"hljs-comment\">// Calculating loss with MSE</span>\n                    loss += <span class=\"hljs-built_in\">sum</span>(<span class=\"hljs-built_in\">apply_function</span>(\n                        cur_error, neural_network::util_functions::square));\n                    <span class=\"hljs-comment\">// If prediction is correct</span>\n                    <span class=\"hljs-keyword\">if</span> (<span class=\"hljs-built_in\">argmax</span>(predicted) == <span class=\"hljs-built_in\">argmax</span>(Y[i])) {\n                        acc += <span class=\"hljs-number\">1</span>;\n                    }\n                    <span class=\"hljs-comment\">// For every layer (except first) starting from last one</span>\n                    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> j = <span class=\"hljs-keyword\">this</span>-&gt;layers.<span class=\"hljs-built_in\">size</span>() - <span class=\"hljs-number\">1</span>; j &gt;= <span class=\"hljs-number\">1</span>; j--) {\n                        <span class=\"hljs-comment\">// Backpropogating errors</span>\n                        cur_error = <span class=\"hljs-built_in\">hadamard_product</span>(\n                            cur_error,\n                            <span class=\"hljs-built_in\">apply_function</span>(\n                                activations[j + <span class=\"hljs-number\">1</span>],\n                                <span class=\"hljs-keyword\">this</span>-&gt;layers[j].dactivation_function));\n                        <span class=\"hljs-comment\">// Calculating gradient for current layer</span>\n                        grad = <span class=\"hljs-built_in\">multiply</span>(<span class=\"hljs-built_in\">transpose</span>(activations[j]), cur_error);\n                        <span class=\"hljs-comment\">// Change error according to current kernel values</span>\n                        cur_error = <span class=\"hljs-built_in\">multiply</span>(cur_error,\n                                             <span class=\"hljs-built_in\">transpose</span>(<span class=\"hljs-keyword\">this</span>-&gt;layers[j].kernel));\n                        <span class=\"hljs-comment\">// Adding gradient values to collection of gradients</span>\n                        gradients[j] = gradients[j] + grad / <span class=\"hljs-built_in\">double</span>(batch_size);\n                    }\n                    <span class=\"hljs-comment\">// Applying gradients</span>\n                    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> j = <span class=\"hljs-keyword\">this</span>-&gt;layers.<span class=\"hljs-built_in\">size</span>() - <span class=\"hljs-number\">1</span>; j &gt;= <span class=\"hljs-number\">1</span>; j--) {\n                        <span class=\"hljs-comment\">// Updating kernel (aka weights)</span>\n                        <span class=\"hljs-keyword\">this</span>-&gt;layers[j].kernel = <span class=\"hljs-keyword\">this</span>-&gt;layers[j].kernel -\n                                                 gradients[j] * learning_rate;\n                    }\n                }\n            }\n            <span class=\"hljs-keyword\">auto</span> stop =\n                std::chrono::high_resolution_clock::<span class=\"hljs-built_in\">now</span>();  <span class=\"hljs-comment\">// Stoping the clock</span>\n            <span class=\"hljs-comment\">// Calculate time taken by epoch</span>\n            <span class=\"hljs-keyword\">auto</span> duration =\n                std::chrono::<span class=\"hljs-built_in\">duration_cast</span>&lt;std::chrono::microseconds&gt;(stop -\n                                                                      start);\n            loss /= X.<span class=\"hljs-built_in\">size</span>();        <span class=\"hljs-comment\">// Averaging loss</span>\n            acc /= X.<span class=\"hljs-built_in\">size</span>();         <span class=\"hljs-comment\">// Averaging accuracy</span>\n            std::cout.<span class=\"hljs-built_in\">precision</span>(<span class=\"hljs-number\">4</span>);  <span class=\"hljs-comment\">// set output precision to 4</span>\n            <span class=\"hljs-comment\">// Printing training stats</span>\n            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Training: Epoch &quot;</span> &lt;&lt; epoch &lt;&lt; <span class=\"hljs-string\">&#x27;/&#x27;</span> &lt;&lt; epochs;\n            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;, Loss: &quot;</span> &lt;&lt; loss;\n            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;, Accuracy: &quot;</span> &lt;&lt; acc;\n            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;, Taken time: &quot;</span> &lt;&lt; duration.<span class=\"hljs-built_in\">count</span>() / <span class=\"hljs-number\">1e6</span>\n                      &lt;&lt; <span class=\"hljs-string\">&quot; seconds&quot;</span>;\n            std::cout &lt;&lt; std::endl;\n        }\n        <span class=\"hljs-keyword\">return</span>;\n    }\n\n    <span class=\"hljs-comment\">/**\n     * Function to fit model on data stored in csv file\n     * @param file_name csv file name\n     * @param last_label flag for whether label is in first or last column\n     * @param epochs number of epochs\n     * @param learning_rate learning rate\n     * @param normalize flag for whether to normalize data\n     * @param slip_lines number of lines to skip\n     * @param batch_size batch size for gradient descent (default = 32)\n     * @param shuffle flag for whether to shuffle data (default = true)\n     */</span>\n    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">fit_from_csv</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> std::string &amp;file_name, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">bool</span> &amp;last_label,\n                      <span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">int</span> &amp;epochs, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">double</span> &amp;learning_rate,\n                      <span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">bool</span> &amp;normalize, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">int</span> &amp;slip_lines = <span class=\"hljs-number\">1</span>,\n                      <span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">size_t</span> &amp;batch_size = <span class=\"hljs-number\">32</span>,\n                      <span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">bool</span> &amp;shuffle = <span class=\"hljs-literal\">true</span>)</span> </span>{\n        <span class=\"hljs-comment\">// Getting training data from csv file</span>\n        <span class=\"hljs-keyword\">auto</span> data =\n            <span class=\"hljs-keyword\">this</span>-&gt;<span class=\"hljs-built_in\">get_XY_from_csv</span>(file_name, last_label, normalize, slip_lines);\n        <span class=\"hljs-comment\">// Fit the model on training data</span>\n        <span class=\"hljs-keyword\">this</span>-&gt;<span class=\"hljs-built_in\">fit</span>(data.first, data.second, epochs, learning_rate, batch_size,\n                  shuffle);\n        <span class=\"hljs-keyword\">return</span>;\n    }\n\n    <span class=\"hljs-comment\">/**\n     * Function to evaluate model on supplied data\n     * @param X array of feature vectors (input data)\n     * @param Y array of target values (label)\n     */</span>\n    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">evaluate</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; &amp;X,\n                  <span class=\"hljs-keyword\">const</span> std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; &amp;Y)</span> </span>{\n        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;INFO: Evaluation Started&quot;</span> &lt;&lt; std::endl;\n        <span class=\"hljs-type\">double</span> acc = <span class=\"hljs-number\">0</span>, loss = <span class=\"hljs-number\">0</span>;  <span class=\"hljs-comment\">// intialize performance metrics with zero</span>\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &lt; X.<span class=\"hljs-built_in\">size</span>(); i++) {  <span class=\"hljs-comment\">// For every sample in input</span>\n            <span class=\"hljs-comment\">// Get predictions</span>\n            std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt; pred =\n                <span class=\"hljs-keyword\">this</span>-&gt;<span class=\"hljs-built_in\">single_predict</span>(X[i]);\n            <span class=\"hljs-comment\">// If predicted class is correct</span>\n            <span class=\"hljs-keyword\">if</span> (<span class=\"hljs-built_in\">argmax</span>(pred) == <span class=\"hljs-built_in\">argmax</span>(Y[i])) {\n                acc += <span class=\"hljs-number\">1</span>;  <span class=\"hljs-comment\">// Increment accuracy</span>\n            }\n            <span class=\"hljs-comment\">// Calculating loss - Mean Squared Error</span>\n            loss += <span class=\"hljs-built_in\">sum</span>(<span class=\"hljs-built_in\">apply_function</span>((Y[i] - pred),\n                                       neural_network::util_functions::square) *\n                        <span class=\"hljs-number\">0.5</span>);\n        }\n        acc /= X.<span class=\"hljs-built_in\">size</span>();   <span class=\"hljs-comment\">// Averaging accuracy</span>\n        loss /= X.<span class=\"hljs-built_in\">size</span>();  <span class=\"hljs-comment\">// Averaging loss</span>\n        <span class=\"hljs-comment\">// Prinitng performance of the model</span>\n        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Evaluation: Loss: &quot;</span> &lt;&lt; loss;\n        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;, Accuracy: &quot;</span> &lt;&lt; acc &lt;&lt; std::endl;\n        <span class=\"hljs-keyword\">return</span>;\n    }\n\n    <span class=\"hljs-comment\">/**\n     * Function to evaluate model on data stored in csv file\n     * @param file_name csv file name\n     * @param last_label flag for whether label is in first or last column\n     * @param normalize flag for whether to normalize data\n     * @param slip_lines number of lines to skip\n     */</span>\n    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">evaluate_from_csv</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> std::string &amp;file_name, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">bool</span> &amp;last_label,\n                           <span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">bool</span> &amp;normalize, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-type\">int</span> &amp;slip_lines = <span class=\"hljs-number\">1</span>)</span> </span>{\n        <span class=\"hljs-comment\">// Getting training data from csv file</span>\n        <span class=\"hljs-keyword\">auto</span> data =\n            <span class=\"hljs-keyword\">this</span>-&gt;<span class=\"hljs-built_in\">get_XY_from_csv</span>(file_name, last_label, normalize, slip_lines);\n        <span class=\"hljs-comment\">// Evaluating model</span>\n        <span class=\"hljs-keyword\">this</span>-&gt;<span class=\"hljs-built_in\">evaluate</span>(data.first, data.second);\n        <span class=\"hljs-keyword\">return</span>;\n    }\n\n    <span class=\"hljs-comment\">/**\n     * Function to save current model.\n     * @param file_name file name to save model (*.model)\n     */</span>\n    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">save_model</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> std::string &amp;_file_name)</span> </span>{\n        std::string file_name = _file_name;\n        <span class=\"hljs-comment\">// Adding &quot;.model&quot; extension if it is not already there in name</span>\n        <span class=\"hljs-keyword\">if</span> (file_name.<span class=\"hljs-built_in\">find</span>(<span class=\"hljs-string\">&quot;.model&quot;</span>) == file_name.npos) {\n            file_name += <span class=\"hljs-string\">&quot;.model&quot;</span>;\n        }\n        std::ofstream out_file;  <span class=\"hljs-comment\">// Ofstream to write in file</span>\n        <span class=\"hljs-comment\">// Open file in out|trunc mode</span>\n        out_file.<span class=\"hljs-built_in\">open</span>(file_name.<span class=\"hljs-built_in\">c_str</span>(),\n                      std::ofstream::out | std::ofstream::trunc);\n        <span class=\"hljs-comment\">// If there is any problem in opening file</span>\n        <span class=\"hljs-keyword\">if</span> (!out_file.<span class=\"hljs-built_in\">is_open</span>()) {\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;Unable to open file: &quot;</span> &lt;&lt; file_name &lt;&lt; std::endl;\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\n        }\n        <span class=\"hljs-comment\">/**\n            Format in which model is saved:\n\n            total_layers\n            neurons(1st neural_network::layers::DenseLayer) activation_name(1st\n           neural_network::layers::DenseLayer) kernel_shape(1st\n           neural_network::layers::DenseLayer) kernel_values\n            .\n            .\n            .\n            neurons(Nth neural_network::layers::DenseLayer) activation_name(Nth\n           neural_network::layers::DenseLayer) kernel_shape(Nth\n           neural_network::layers::DenseLayer) kernel_value\n\n            For Example, pretrained model with 3 layers:\n            &lt;pre&gt;\n            3\n            4 none\n            4 4\n            1 0 0 0\n            0 1 0 0\n            0 0 1 0\n            0 0 0 1\n            6 relu\n            4 6\n            -1.88963 -3.61165 1.30757 -0.443906 -2.41039 -2.69653\n            -0.684753 0.0891452 0.795294 -2.39619 2.73377 0.318202\n            -2.91451 -4.43249 -0.804187 2.51995 -6.97524 -1.07049\n            -0.571531 -1.81689 -1.24485 1.92264 -2.81322 1.01741\n            3 sigmoid\n            6 3\n            0.390267 -0.391703 -0.0989607\n            0.499234 -0.564539 -0.28097\n            0.553386 -0.153974 -1.92493\n            -2.01336 -0.0219682 1.44145\n            1.72853 -0.465264 -0.705373\n            -0.908409 -0.740547 0.376416\n            &lt;/pre&gt;\n        */</span>\n        <span class=\"hljs-comment\">// Saving model in the same format</span>\n        out_file &lt;&lt; layers.<span class=\"hljs-built_in\">size</span>();\n        out_file &lt;&lt; std::endl;\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">auto</span> &amp;layer : <span class=\"hljs-keyword\">this</span>-&gt;layers) {\n            out_file &lt;&lt; layer.neurons &lt;&lt; <span class=\"hljs-string\">&#x27; &#x27;</span> &lt;&lt; layer.activation &lt;&lt; std::endl;\n            <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">auto</span> shape = <span class=\"hljs-built_in\">get_shape</span>(layer.kernel);\n            out_file &lt;&lt; shape.first &lt;&lt; <span class=\"hljs-string\">&#x27; &#x27;</span> &lt;&lt; shape.second &lt;&lt; std::endl;\n            <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">auto</span> &amp;row : layer.kernel) {\n                <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">auto</span> &amp;val : row) {\n                    out_file &lt;&lt; val &lt;&lt; <span class=\"hljs-string\">&#x27; &#x27;</span>;\n                }\n                out_file &lt;&lt; std::endl;\n            }\n        }\n        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;INFO: Model saved successfully with name : &quot;</span>;\n        std::cout &lt;&lt; file_name &lt;&lt; std::endl;\n        out_file.<span class=\"hljs-built_in\">close</span>();  <span class=\"hljs-comment\">// Closing file</span>\n        <span class=\"hljs-keyword\">return</span>;\n    }\n\n    <span class=\"hljs-comment\">/**\n     * Function to load earlier saved model.\n     * @param file_name file from which model will be loaded (*.model)\n     * @return instance of NeuralNetwork class with pretrained weights\n     */</span>\n    <span class=\"hljs-function\">NeuralNetwork <span class=\"hljs-title\">load_model</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> std::string &amp;file_name)</span> </span>{\n        std::ifstream in_file;            <span class=\"hljs-comment\">// Ifstream to read file</span>\n        in_file.<span class=\"hljs-built_in\">open</span>(file_name.<span class=\"hljs-built_in\">c_str</span>());  <span class=\"hljs-comment\">// Openinig file</span>\n        <span class=\"hljs-comment\">// If there is any problem in opening file</span>\n        <span class=\"hljs-keyword\">if</span> (!in_file.<span class=\"hljs-built_in\">is_open</span>()) {\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;Unable to open file: &quot;</span> &lt;&lt; file_name &lt;&lt; std::endl;\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\n        }\n        std::vector&lt;std::pair&lt;<span class=\"hljs-type\">int</span>, std::string&gt;&gt; config;  <span class=\"hljs-comment\">// To store config</span>\n        std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt;\n            kernels;  <span class=\"hljs-comment\">// To store pretrained kernels</span>\n        <span class=\"hljs-comment\">// Loading model from saved file format</span>\n        <span class=\"hljs-type\">size_t</span> total_layers = <span class=\"hljs-number\">0</span>;\n        in_file &gt;&gt; total_layers;\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &lt; total_layers; i++) {\n            <span class=\"hljs-type\">int</span> neurons = <span class=\"hljs-number\">0</span>;\n            std::string activation;\n            <span class=\"hljs-type\">size_t</span> shape_a = <span class=\"hljs-number\">0</span>, shape_b = <span class=\"hljs-number\">0</span>;\n            std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt; kernel;\n            in_file &gt;&gt; neurons &gt;&gt; activation &gt;&gt; shape_a &gt;&gt; shape_b;\n            <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> r = <span class=\"hljs-number\">0</span>; r &lt; shape_a; r++) {\n                <span class=\"hljs-function\">std::valarray&lt;<span class=\"hljs-type\">double</span>&gt; <span class=\"hljs-title\">row</span><span class=\"hljs-params\">(shape_b)</span></span>;\n                <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> c = <span class=\"hljs-number\">0</span>; c &lt; shape_b; c++) {\n                    in_file &gt;&gt; row[c];\n                }\n                kernel.<span class=\"hljs-built_in\">push_back</span>(row);\n            }\n            config.<span class=\"hljs-built_in\">emplace_back</span>(<span class=\"hljs-built_in\">make_pair</span>(neurons, activation));\n            ;\n            kernels.<span class=\"hljs-built_in\">emplace_back</span>(kernel);\n        }\n        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;INFO: Model loaded successfully&quot;</span> &lt;&lt; std::endl;\n        in_file.<span class=\"hljs-built_in\">close</span>();  <span class=\"hljs-comment\">// Closing file</span>\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">NeuralNetwork</span>(\n            config, kernels);  <span class=\"hljs-comment\">// Return instance of NeuralNetwork class</span>\n    }\n\n    <span class=\"hljs-comment\">/**\n     * Function to print summary of the network.\n     */</span>\n    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">summary</span><span class=\"hljs-params\">()</span> </span>{\n        <span class=\"hljs-comment\">// Printing Summary</span>\n        std::cout\n            &lt;&lt; <span class=\"hljs-string\">&quot;===============================================================&quot;</span>\n            &lt;&lt; std::endl;\n        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;\\t\\t+ MODEL SUMMARY +\\t\\t\\n&quot;</span>;\n        std::cout\n            &lt;&lt; <span class=\"hljs-string\">&quot;===============================================================&quot;</span>\n            &lt;&lt; std::endl;\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">1</span>; i &lt;= layers.<span class=\"hljs-built_in\">size</span>(); i++) {  <span class=\"hljs-comment\">// For every layer</span>\n            std::cout &lt;&lt; i &lt;&lt; <span class=\"hljs-string\">&quot;)&quot;</span>;\n            std::cout &lt;&lt; <span class=\"hljs-string\">&quot; Neurons : &quot;</span>\n                      &lt;&lt; layers[i - <span class=\"hljs-number\">1</span>].neurons;  <span class=\"hljs-comment\">// number of neurons</span>\n            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;, Activation : &quot;</span>\n                      &lt;&lt; layers[i - <span class=\"hljs-number\">1</span>].activation;  <span class=\"hljs-comment\">// activation</span>\n            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;, kernel Shape : &quot;</span>\n                      &lt;&lt; <span class=\"hljs-built_in\">get_shape</span>(layers[i - <span class=\"hljs-number\">1</span>].kernel);  <span class=\"hljs-comment\">// kernel shape</span>\n            std::cout &lt;&lt; std::endl;\n        }\n        std::cout\n            &lt;&lt; <span class=\"hljs-string\">&quot;===============================================================&quot;</span>\n            &lt;&lt; std::endl;\n        <span class=\"hljs-keyword\">return</span>;\n    }\n};\n}  <span class=\"hljs-comment\">// namespace neural_network</span>\n}  <span class=\"hljs-comment\">// namespace machine_learning</span>\n\n<span class=\"hljs-comment\">/**\n * Function to test neural network\n * @returns none\n */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">test</span><span class=\"hljs-params\">()</span> </span>{\n    <span class=\"hljs-comment\">// Creating network with 3 layers for &quot;iris.csv&quot;</span>\n    machine_learning::neural_network::NeuralNetwork myNN =\n        machine_learning::neural_network::<span class=\"hljs-built_in\">NeuralNetwork</span>({\n            {<span class=\"hljs-number\">4</span>, <span class=\"hljs-string\">&quot;none&quot;</span>},  <span class=\"hljs-comment\">// First layer with 3 neurons and &quot;none&quot; as activation</span>\n            {<span class=\"hljs-number\">6</span>,\n             <span class=\"hljs-string\">&quot;relu&quot;</span>},  <span class=\"hljs-comment\">// Second layer with 6 neurons and &quot;relu&quot; as activation</span>\n            {<span class=\"hljs-number\">3</span>, <span class=\"hljs-string\">&quot;sigmoid&quot;</span>}  <span class=\"hljs-comment\">// Third layer with 3 neurons and &quot;sigmoid&quot; as</span>\n                            <span class=\"hljs-comment\">// activation</span>\n        });\n    <span class=\"hljs-comment\">// Printing summary of model</span>\n    myNN.<span class=\"hljs-built_in\">summary</span>();\n    <span class=\"hljs-comment\">// Training Model</span>\n    myNN.<span class=\"hljs-built_in\">fit_from_csv</span>(<span class=\"hljs-string\">&quot;iris.csv&quot;</span>, <span class=\"hljs-literal\">true</span>, <span class=\"hljs-number\">100</span>, <span class=\"hljs-number\">0.3</span>, <span class=\"hljs-literal\">false</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">32</span>, <span class=\"hljs-literal\">true</span>);\n    <span class=\"hljs-comment\">// Testing predictions of model</span>\n    <span class=\"hljs-built_in\">assert</span>(machine_learning::<span class=\"hljs-built_in\">argmax</span>(\n               myNN.<span class=\"hljs-built_in\">single_predict</span>({{<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3.4</span>, <span class=\"hljs-number\">1.6</span>, <span class=\"hljs-number\">0.4</span>}})) == <span class=\"hljs-number\">0</span>);\n    <span class=\"hljs-built_in\">assert</span>(machine_learning::<span class=\"hljs-built_in\">argmax</span>(\n               myNN.<span class=\"hljs-built_in\">single_predict</span>({{<span class=\"hljs-number\">6.4</span>, <span class=\"hljs-number\">2.9</span>, <span class=\"hljs-number\">4.3</span>, <span class=\"hljs-number\">1.3</span>}})) == <span class=\"hljs-number\">1</span>);\n    <span class=\"hljs-built_in\">assert</span>(machine_learning::<span class=\"hljs-built_in\">argmax</span>(\n               myNN.<span class=\"hljs-built_in\">single_predict</span>({{<span class=\"hljs-number\">6.2</span>, <span class=\"hljs-number\">3.4</span>, <span class=\"hljs-number\">5.4</span>, <span class=\"hljs-number\">2.3</span>}})) == <span class=\"hljs-number\">2</span>);\n    <span class=\"hljs-keyword\">return</span>;\n}\n\n<span class=\"hljs-comment\">/**\n * @brief Main function\n * @returns 0 on exit\n */</span>\n<span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>{\n    <span class=\"hljs-comment\">// Testing</span>\n    <span class=\"hljs-built_in\">test</span>();\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n}\n"
    }
  },
  "contributors": [
    {
      "name": "Deep Raval",
      "email": "deepraval2905@gmail.com",
      "commits": 4
    }
  ],
  "explanationUrl": {}
}
