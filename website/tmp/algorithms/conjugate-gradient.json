{
  "slug": "conjugate-gradient",
  "name": "Conjugate Gradient",
  "categories": ["linearalgebra", "src"],
  "body": {},
  "implementations": {
    "python": {
      "dir": "linear_algebra/src/conjugate_gradient.py",
      "url": "https://github.com/TheAlgorithms/python/tree/master/linear_algebra/src/conjugate_gradient.py",
      "code": "<span class=\"hljs-string\">&quot;&quot;&quot;\nResources:\n- https://en.wikipedia.org/wiki/Conjugate_gradient_method\n- https://en.wikipedia.org/wiki/Definite_symmetric_matrix\n&quot;&quot;&quot;</span>\n<span class=\"hljs-keyword\">from</span> typing <span class=\"hljs-keyword\">import</span> <span class=\"hljs-type\">Any</span>\n\n<span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np\n\n\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">_is_matrix_spd</span>(<span class=\"hljs-params\">matrix: np.ndarray</span>) -&gt; <span class=\"hljs-built_in\">bool</span>:\n    <span class=\"hljs-string\">&quot;&quot;&quot;\n    Returns True if input matrix is symmetric positive definite.\n    Returns False otherwise.\n\n    For a matrix to be SPD, all eigenvalues must be positive.\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; matrix = np.array([\n    ... [4.12401784, -5.01453636, -0.63865857],\n    ... [-5.01453636, 12.33347422, -3.40493586],\n    ... [-0.63865857, -3.40493586,  5.78591885]])\n    &gt;&gt;&gt; _is_matrix_spd(matrix)\n    True\n    &gt;&gt;&gt; matrix = np.array([\n    ... [0.34634879,  1.96165514,  2.18277744],\n    ... [0.74074469, -1.19648894, -1.34223498],\n    ... [-0.7687067 ,  0.06018373, -1.16315631]])\n    &gt;&gt;&gt; _is_matrix_spd(matrix)\n    False\n    &quot;&quot;&quot;</span>\n    <span class=\"hljs-comment\"># Ensure matrix is square.</span>\n    <span class=\"hljs-keyword\">assert</span> np.shape(matrix)[<span class=\"hljs-number\">0</span>] == np.shape(matrix)[<span class=\"hljs-number\">1</span>]\n\n    <span class=\"hljs-comment\"># If matrix not symmetric, exit right away.</span>\n    <span class=\"hljs-keyword\">if</span> np.allclose(matrix, matrix.T) <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">False</span>:\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">False</span>\n\n    <span class=\"hljs-comment\"># Get eigenvalues and eignevectors for a symmetric matrix.</span>\n    eigen_values, _ = np.linalg.eigh(matrix)\n\n    <span class=\"hljs-comment\"># Check sign of all eigenvalues.</span>\n    <span class=\"hljs-comment\"># np.all returns a value of type np.bool_</span>\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">bool</span>(np.<span class=\"hljs-built_in\">all</span>(eigen_values &gt; <span class=\"hljs-number\">0</span>))\n\n\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">_create_spd_matrix</span>(<span class=\"hljs-params\">dimension: <span class=\"hljs-built_in\">int</span></span>) -&gt; <span class=\"hljs-type\">Any</span>:\n    <span class=\"hljs-string\">&quot;&quot;&quot;\n    Returns a symmetric positive definite matrix given a dimension.\n\n    Input:\n    dimension gives the square matrix dimension.\n\n    Output:\n    spd_matrix is an diminesion x dimensions symmetric positive definite (SPD) matrix.\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; dimension = 3\n    &gt;&gt;&gt; spd_matrix = _create_spd_matrix(dimension)\n    &gt;&gt;&gt; _is_matrix_spd(spd_matrix)\n    True\n    &quot;&quot;&quot;</span>\n    random_matrix = np.random.randn(dimension, dimension)\n    spd_matrix = np.dot(random_matrix, random_matrix.T)\n    <span class=\"hljs-keyword\">assert</span> _is_matrix_spd(spd_matrix)\n    <span class=\"hljs-keyword\">return</span> spd_matrix\n\n\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">conjugate_gradient</span>(<span class=\"hljs-params\">\n    spd_matrix: np.ndarray,\n    load_vector: np.ndarray,\n    max_iterations: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">1000</span>,\n    tol: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">1e-8</span>,\n</span>) -&gt; <span class=\"hljs-type\">Any</span>:\n    <span class=\"hljs-string\">&quot;&quot;&quot;\n    Returns solution to the linear system np.dot(spd_matrix, x) = b.\n\n    Input:\n    spd_matrix is an NxN Symmetric Positive Definite (SPD) matrix.\n    load_vector is an Nx1 vector.\n\n    Output:\n    x is an Nx1 vector that is the solution vector.\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; spd_matrix = np.array([\n    ... [8.73256573, -5.02034289, -2.68709226],\n    ... [-5.02034289,  3.78188322,  0.91980451],\n    ... [-2.68709226,  0.91980451,  1.94746467]])\n    &gt;&gt;&gt; b = np.array([\n    ... [-5.80872761],\n    ... [ 3.23807431],\n    ... [ 1.95381422]])\n    &gt;&gt;&gt; conjugate_gradient(spd_matrix, b)\n    array([[-0.63114139],\n           [-0.01561498],\n           [ 0.13979294]])\n    &quot;&quot;&quot;</span>\n    <span class=\"hljs-comment\"># Ensure proper dimensionality.</span>\n    <span class=\"hljs-keyword\">assert</span> np.shape(spd_matrix)[<span class=\"hljs-number\">0</span>] == np.shape(spd_matrix)[<span class=\"hljs-number\">1</span>]\n    <span class=\"hljs-keyword\">assert</span> np.shape(load_vector)[<span class=\"hljs-number\">0</span>] == np.shape(spd_matrix)[<span class=\"hljs-number\">0</span>]\n    <span class=\"hljs-keyword\">assert</span> _is_matrix_spd(spd_matrix)\n\n    <span class=\"hljs-comment\"># Initialize solution guess, residual, search direction.</span>\n    x0 = np.zeros((np.shape(load_vector)[<span class=\"hljs-number\">0</span>], <span class=\"hljs-number\">1</span>))\n    r0 = np.copy(load_vector)\n    p0 = np.copy(r0)\n\n    <span class=\"hljs-comment\"># Set initial errors in solution guess and residual.</span>\n    error_residual = <span class=\"hljs-number\">1e9</span>\n    error_x_solution = <span class=\"hljs-number\">1e9</span>\n    error = <span class=\"hljs-number\">1e9</span>\n\n    <span class=\"hljs-comment\"># Set iteration counter to threshold number of iterations.</span>\n    iterations = <span class=\"hljs-number\">0</span>\n\n    <span class=\"hljs-keyword\">while</span> error &gt; tol:\n\n        <span class=\"hljs-comment\"># Save this value so we only calculate the matrix-vector product once.</span>\n        w = np.dot(spd_matrix, p0)\n\n        <span class=\"hljs-comment\"># The main algorithm.</span>\n\n        <span class=\"hljs-comment\"># Update search direction magnitude.</span>\n        alpha = np.dot(r0.T, r0) / np.dot(p0.T, w)\n        <span class=\"hljs-comment\"># Update solution guess.</span>\n        x = x0 + alpha * p0\n        <span class=\"hljs-comment\"># Calculate new residual.</span>\n        r = r0 - alpha * w\n        <span class=\"hljs-comment\"># Calculate new Krylov subspace scale.</span>\n        beta = np.dot(r.T, r) / np.dot(r0.T, r0)\n        <span class=\"hljs-comment\"># Calculate new A conjuage search direction.</span>\n        p = r + beta * p0\n\n        <span class=\"hljs-comment\"># Calculate errors.</span>\n        error_residual = np.linalg.norm(r - r0)\n        error_x_solution = np.linalg.norm(x - x0)\n        error = np.maximum(error_residual, error_x_solution)\n\n        <span class=\"hljs-comment\"># Update variables.</span>\n        x0 = np.copy(x)\n        r0 = np.copy(r)\n        p0 = np.copy(p)\n\n        <span class=\"hljs-comment\"># Update number of iterations.</span>\n        iterations += <span class=\"hljs-number\">1</span>\n        <span class=\"hljs-keyword\">if</span> iterations &gt; max_iterations:\n            <span class=\"hljs-keyword\">break</span>\n\n    <span class=\"hljs-keyword\">return</span> x\n\n\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">test_conjugate_gradient</span>() -&gt; <span class=\"hljs-literal\">None</span>:\n    <span class=\"hljs-string\">&quot;&quot;&quot;\n    &gt;&gt;&gt; test_conjugate_gradient()  # self running tests\n    &quot;&quot;&quot;</span>\n    <span class=\"hljs-comment\"># Create linear system with SPD matrix and known solution x_true.</span>\n    dimension = <span class=\"hljs-number\">3</span>\n    spd_matrix = _create_spd_matrix(dimension)\n    x_true = np.random.randn(dimension, <span class=\"hljs-number\">1</span>)\n    b = np.dot(spd_matrix, x_true)\n\n    <span class=\"hljs-comment\"># Numpy solution.</span>\n    x_numpy = np.linalg.solve(spd_matrix, b)\n\n    <span class=\"hljs-comment\"># Our implementation.</span>\n    x_conjugate_gradient = conjugate_gradient(spd_matrix, b)\n\n    <span class=\"hljs-comment\"># Ensure both solutions are close to x_true (and therefore one another).</span>\n    <span class=\"hljs-keyword\">assert</span> np.linalg.norm(x_numpy - x_true) &lt;= <span class=\"hljs-number\">1e-6</span>\n    <span class=\"hljs-keyword\">assert</span> np.linalg.norm(x_conjugate_gradient - x_true) &lt;= <span class=\"hljs-number\">1e-6</span>\n\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">&quot;__main__&quot;</span>:\n    <span class=\"hljs-keyword\">import</span> doctest\n\n    doctest.testmod()\n    test_conjugate_gradient()\n"
    }
  },
  "contributors": [
    {
      "name": "Dhruv Manilawala",
      "email": "dhruvmanila@gmail.com",
      "commits": 1
    },
    {
      "name": "zakademic",
      "email": "67771932+zakademic@users.noreply.github.com",
      "commits": 1
    }
  ],
  "explanationUrl": {}
}
